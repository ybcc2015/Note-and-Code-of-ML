{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯 (Naive Bayes)\n",
    "朴素贝叶斯是一个简单且常用的分类算法，其基于两个条件：\n",
    "1. 贝叶斯定理\n",
    "2. 特征条件独立假设"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.模型定义\n",
    "设输入数据$x \\in R^n$，输出类别$y=\\{c_1,c_2,...,c_K\\}$，X是输入空间中的随机向量，Y是输出空间中的随机变量，则有    \n",
    "联合概率分布：$P(X,Y)$    \n",
    "先验概率分布：$P(Y=c_k),\\quad k=1,2,...,K$    \n",
    "条件概率分布：$P(X=x\\mid Y=c_k)=P(X^1=x^1,...,X^n=x^n\\mid Y=c_k),\\quad k=1,2,...,K$    \n",
    "朴素贝叶斯就是通过**条件概率分布**和**先验分布**来学习**联合概率分布**。  \n",
    "  \n",
    "之所以称为**朴素**贝叶斯，是因为对条件概率分布作了条件独立假设，即：$$P(X=x\\mid Y=c_k)=P(X^1=x^1,...,X^n=x^n\\mid Y=c_k)=\\prod_{j=1}^nP(X^j=x^j\\mid Y=c_k)$$  \n",
    "**条件独立假设**是指用于分类的特征在类别确定的条件下都是独立的，这一假设使得朴素贝叶斯算法更加简单，但有时会牺牲分类的准确率。  \n",
    "  \n",
    "朴素贝叶斯模型对输入x计算后验概率$P(Y=c_k\\mid X=x)$，将后验概率最大的类作为x的分类结果。后验概率根据贝叶斯定理计算：$$P(Y=c_k\\mid X=x)=\\frac{P(X=x\\mid Y=c_k)P(Y=c_k)}{\\sum_{k}P(X=x\\mid Y=c_k)P(Y=c_k)}$$  \n",
    "由条件独立，可得：$$P(Y=c_k\\mid X=x)=\\frac{P(Y=c_k)\\prod_{j}P(X^j=x^j\\mid Y=c_k)}{\\sum_{k}P(Y=c_k)\\prod_{j}P(X^j=x^j\\mid Y=c_k)}$$  \n",
    "因此，朴素贝叶斯模型可以表示为：$$y=argmax_{C_k}\\frac{P(Y=c_k)\\prod_{j}P(X^j=x^j\\mid Y=c_k)}{\\sum_{k}P(Y=c_k)\\prod_{j}P(X^j=x^j\\mid Y=c_k)}$$  \n",
    "又由于上式中分母是不变的，所以可以简化为：$$y=argmax_{C_k}P(Y=c_k)\\prod_{j}P(X^j=x^j\\mid Y=c_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.极大似然估计\n",
    "在朴素贝叶斯算法中，通常用极大似然估计来计算先验概率$P(Y=c_k)$和条件概率$P(X^j=x^j\\mid Y=c_k)$。 \n",
    "  \n",
    "先验概率$P(Y=c_k)$的极大似然估计：$$P(Y=c_k)=\\frac{\\sum_{i=1}^{N}I(y_i=c_k)}{N}$$ \n",
    "  \n",
    "设第j个特征$x^j\\in\\{a_{j1},a_{j2},...,a_{jS_{j}}\\}$，条件概率$P(X^j=a_{jl}\\mid Y=c_k)$的极大似然估计：$$P(X^j=a_{jl}\\mid Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^j=a_{jl},y_i=c_k)}{\\sum_{i=1}^{N}I(y_i=c_k)}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.算法流程\n",
    "假设训练集 $T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$，特征维度为$n$，$x_i^j\\in\\{a_{j1},a_{j2},...,a_{jS_{j}}\\}$表示第$j$个特征可取的值，$a_{jl}$表示第$j$个特征取的第$l$个值，$j=1,2,...,n;\\quad l=1,2,...,S_j;\\quad y_i\\in\\{c_1,c_2,...,c_k\\}$，则朴素贝叶斯算法流程如下：  \n",
    "1. 计算先验概率和条件概率：$$P(Y=c_k)=\\frac{\\sum_{i=1}^{N}I(y_i=c_k)}{N}$$ \n",
    "$$P(X^j=a_{jl}\\mid Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^j=a_{jl},y_i=c_k)}{\\sum_{i=1}^{N}I(y_i=c_k)}$$\n",
    "2. 对于测试样本$x=(x^1,x^2,...,x^n)^T$，计算：$$P(Y=c_k)\\prod_{j=1}^{n}P(X^j=x^j\\mid Y=c_k)$$  \n",
    "3. 确定测试样本$x$的类别：$$y=argmax_{C_k}P(Y=c_k)\\prod_{j=1}^{n}P(X^j=x^j\\mid Y=c_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.拉普拉斯平滑\n",
    "极大似然估计有个弊端，当有一个新样本$x$，如果它的第$j$个特征值是在训练集中未见过时，会导致$P(X^j=x^j\\mid Y=c_k)$等于0，这会使得后验概率的结果始终为0，从而无法将这个样本分类。 \n",
    "  \n",
    "解决这一问题的方法是采用**拉普拉斯平滑**，其思想就是让分子和分母分别加上一个常数，使得结果不能为0。  \n",
    "对于条件概率，分子加1，分母加上当前特征在训练集中可取值的数量，即：$$P(X^j=a_{jl}\\mid Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^j=a_{jl},y_i=c_k)+1}{\\sum_{i=1}^{N}I(y_i=c_k)+S_{j}}$$  \n",
    "对于先验概率，分子加1，分母加上类别数量，即：$$P(Y=c_k)=\\frac{\\sum_{i=1}^{N}I(y_i=c_k)+1}{N+K}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Code\n",
    "code time :-）这里使用《统计学习方法》书上的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 numpy版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_datas = np.array([\n",
    "    [1,'S',-1], [1,'M',-1], [1,'M',1], [1,'S',1], [1,'S',-1], \n",
    "    [2,'S',-1], [2,'M',-1], [2,'M',1], [2,'L',1], [2,'L',1],\n",
    "    [3,'L',1], [3,'M',1], [3,'M',1], [3,'L',1], [3,'L',-1]\n",
    "])\n",
    "X = train_datas[:, :2]\n",
    "Y = train_datas[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.N = X.shape[0]  # 训练集大小\n",
    "        self.n = X.shape[1]  # 特征个数\n",
    "        self.classes = np.unique(Y)  # 类别可取值\n",
    "        self.K = self.classes.size  # 类别总数\n",
    "        self.prior_prob = None\n",
    "        self.cond_prob = None\n",
    "        self.poster_prob = None\n",
    "        \n",
    "    def get_prior_prob(self):\n",
    "        \"\"\"\n",
    "        计算每个类别的先验概率\n",
    "        \"\"\"\n",
    "        prior_prob = {}\n",
    "        for c in self.classes:\n",
    "            _sum = np.sum(np.where(self.Y==c, 1, 0))\n",
    "            key = 'Y={}'.format(c)\n",
    "            prior_prob[key] = (_sum + 1) / (self.N + self.K)  # Laplace smoothing\n",
    "        return prior_prob\n",
    "    \n",
    "    def get_conditional_prob(self):\n",
    "        \"\"\"\n",
    "        计算每个特征值在特定类别下的条件概率\n",
    "        \"\"\"\n",
    "        cond_prob = {}\n",
    "        # 遍历每一类\n",
    "        for c in self.classes:\n",
    "            inds = np.where(self.Y==c)[0]\n",
    "            datas = X[inds]  # 类别为c的所有样本\n",
    "            # 遍历每个特征\n",
    "            for j in range(self.n):\n",
    "                a = X[:, j]\n",
    "                values = np.unique(a)  # 特征a的可取值\n",
    "                Sj = values.size  # 特征a的可取值数量\n",
    "                for v in values:\n",
    "                    _sum = np.sum(np.where(datas[:, j]==v, 1, 0))\n",
    "                    key = 'X{}={}|Y={}'.format(j+1, v, c)\n",
    "                    cond_prob[key] = (_sum + 1) / (len(datas) + Sj)  # Laplace smoothing\n",
    "        return cond_prob\n",
    "                    \n",
    "    def fit(self):\n",
    "        self.prior_prob = self.get_prior_prob()\n",
    "        self.cond_prob = self.get_conditional_prob()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        poster_prob = {}\n",
    "        for c in self.classes:\n",
    "            prob = 1.0\n",
    "            prior_key = 'Y={}'.format(c)\n",
    "            prob *= self.prior_prob[prior_key]\n",
    "            for j in range(self.n):\n",
    "                cond_key = 'X{}={}|Y={}'.format(j+1, x[j], c)\n",
    "                if cond_key in self.cond_prob.keys():\n",
    "                    cond_prob = self.cond_prob[cond_key]\n",
    "                else:\n",
    "                    cond_prob = 1 / (np.sum(np.where(self.Y==c, 1, 0)) + np.unique(self.X[:, j]).size)\n",
    "                prob *= cond_prob\n",
    "            poster_prob[c] = prob\n",
    "        self.poster_prob = poster_prob\n",
    "        cls = sorted(poster_prob.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "model = NaiveBayes(X, Y)\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Y=-1': 0.4117647058823529, 'Y=1': 0.5882352941176471}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先验概率\n",
    "model.prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1=1|Y=-1': 0.4444444444444444,\n",
       " 'X1=1|Y=1': 0.25,\n",
       " 'X1=2|Y=-1': 0.3333333333333333,\n",
       " 'X1=2|Y=1': 0.3333333333333333,\n",
       " 'X1=3|Y=-1': 0.2222222222222222,\n",
       " 'X1=3|Y=1': 0.4166666666666667,\n",
       " 'X2=L|Y=-1': 0.2222222222222222,\n",
       " 'X2=L|Y=1': 0.4166666666666667,\n",
       " 'X2=M|Y=-1': 0.3333333333333333,\n",
       " 'X2=M|Y=1': 0.4166666666666667,\n",
       " 'X2=S|Y=-1': 0.4444444444444444,\n",
       " 'X2=S|Y=1': 0.16666666666666666}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 条件概率\n",
    "model.cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "后验概率: {'-1': 0.06100217864923746, '1': 0.0326797385620915}\n",
      "预测结果: -1\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "x = np.array([2, 'S'])\n",
    "y = model.predict(x)\n",
    "print('后验概率:', model.poster_prob)\n",
    "print('预测结果:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 sklearn版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理，将类别型转换为数值型\n",
    "le = LabelEncoder()\n",
    "A2 = le.fit_transform(X[:,1])\n",
    "X_train = np.c_[X[:, 0].astype(np.int32), A2]\n",
    "Y_train = Y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测\n",
    "x = np.array([[2, 'S']])\n",
    "x = np.c_[x[:, 0].astype(np.int32), le.transform(x[:, 1])]\n",
    "clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_proba() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-054b16ed0f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: predict_proba() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
